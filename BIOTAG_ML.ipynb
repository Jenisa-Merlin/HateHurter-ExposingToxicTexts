{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4OR3dm7nPB1F+uPwaAvFf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jenisa-Merlin/HateHurter-ExposingToxicTexts/blob/main/BIOTAG_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SVzFKat0-Nq"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "import nltk\n",
        "!pip install sklearn_crfsuite\n",
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "!pip uninstall sklearn-crfsuite\n",
        "!pip install sklearn-crfsuite\n",
        "!pip install -U scikit-learn\n",
        "from sklearn_crfsuite import CRF\n",
        "import sklearn_crfsuite.metrics as metrics\n",
        "import joblib\n",
        "!pip install Flask\n",
        "from flask import Flask, request, jsonify, render_template"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "data = pd.read_csv(\"data.csv\", encoding=\"latin-1\")\n",
        "data.drop_duplicates(inplace=True)\n",
        "data.dropna(inplace=True)\n",
        "data['sentence'] = data['sentence'].apply(lambda x: x.lower())"
      ],
      "metadata": {
        "id": "nyquHs9y1RUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(data):\n",
        "    sentences = []\n",
        "    labels = []\n",
        "    for item in data:\n",
        "        sentence = data[\"sentence\"].str.split()\n",
        "        bio_labels = data[\"bio\"].str.split()\n",
        "        sentences.append(sentence)\n",
        "        labels.append(bio_labels)\n",
        "    return sentences, labels\n",
        "sentences, labels = prepare_data(data)"
      ],
      "metadata": {
        "id": "Jf_lwrw22I2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def word2features(sent, i):\n",
        "    word = sent[i]  # 'word' should be an individual token\n",
        "    features = {\n",
        "        'bias': 1.0,\n",
        "        'word.lower()': word.lower(),\n",
        "        'word[-3:]': word[-3:],\n",
        "        'word.isupper()': word.isupper(),\n",
        "        'word.istitle()': word.istitle(),\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word.lower()': word1.lower(),\n",
        "            '-1:word.istitle()': word1.istitle(),\n",
        "            '-1:word.isupper()': word1.isupper(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word.lower()': word1.lower(),\n",
        "            '+1:word.istitle()': word1.istitle(),\n",
        "            '+1:word.isupper()': word1.isupper(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "    return features\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]"
      ],
      "metadata": {
        "id": "P_kpX4bG2SUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = data['sentence'].str.split()\n",
        "labels = data['bio'].str.split()\n",
        "X = [sent2features(sent) for sent in sentences]\n",
        "y = labels"
      ],
      "metadata": {
        "id": "Z7m-5vGMAoWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (sentence, label) in enumerate(zip(sentences, labels), start=1):\n",
        "    if len(sentence) != len(label):\n",
        "        print(f\"Mismatch found in sentence {i}:\")\n",
        "        print(f\"Sentence tokens: {sentence}\")\n",
        "        print(f\"BIO labels: {label}\")"
      ],
      "metadata": {
        "id": "F_wnJxiK2f_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "3IwjBvfy2lPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crf = CRF(\n",
        "    algorithm='lbfgs',\n",
        "    c1=0.1,\n",
        "    c2=0.1,\n",
        "    max_iterations=100,\n",
        "    all_possible_transitions=True,\n",
        ")\n",
        "try:\n",
        "    crf.fit(X_train, y_train)\n",
        "except AttributeError:\n",
        "    pass"
      ],
      "metadata": {
        "id": "sffosNi1EOWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = crf.predict(X_val)\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "7D95rVT62sve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_sentence = input(\"Enter the sentence to predict BIO tags : \")\n",
        "new_sentence_tokens = new_sentence.split()\n",
        "new_sentence_features = sent2features(new_sentence_tokens)\n",
        "predicted_tags = crf.predict([new_sentence_features])[0]\n",
        "print(\"Predicted BIO Tags:\", predicted_tags)"
      ],
      "metadata": {
        "id": "xutfc1Zr3I0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score = metrics.flat_f1_score(y_val, predictions, average='weighted')\n",
        "precision = metrics.flat_precision_score(y_val, predictions, average='weighted')\n",
        "recall = metrics.flat_recall_score(y_val, predictions, average='weighted')\n",
        "accuracy = metrics.flat_accuracy_score(y_val, predictions)\n",
        "print(f\"F1 score: {f1_score:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "kkTbKyJVCYg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = y_val.value_counts()\n",
        "print(\"Support for each class:\")\n",
        "print(class_counts)"
      ],
      "metadata": {
        "id": "SWpAlGn-GAyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(crf, '/content/drive/MyDrive/MLPROJECT/crf_model.pkl')"
      ],
      "metadata": {
        "id": "Lk9v9gwvHJxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = Flask(__name__)\n",
        "crf_model = joblib.load(\"/content/drive/MyDrive/MLPROJECT/crf_model.pkl\")\n",
        "@app.route('/')\n",
        "def front():\n",
        "    return render_template('/content/drive/MyDrive/MLPROJECT/templates/front.html')\n",
        "@app.route('/api/detect-hate-span', methods=['POST'])\n",
        "def detect_hate_span():\n",
        "    data = request.get_json()\n",
        "    sentence = data.get('sentence', '')\n",
        "    predicted_tags = predict_hate_span(sentence)\n",
        "    result = {\n",
        "        \"sentence\": sentence,\n",
        "        \"hateSpeechWords\": predicted_tags\n",
        "    }\n",
        "    return jsonify(result)\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'bias': 1.0,\n",
        "        'word.lower()': word.lower(),\n",
        "        'word[-3:]': word[-3:],\n",
        "        'word.isupper()': word.isupper(),\n",
        "        'word.istitle()': word.istitle(),\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i - 1]\n",
        "        features.update({\n",
        "            '-1:word.lower()': word1.lower(),\n",
        "            '-1:word.istitle()': word1.istitle(),\n",
        "            '-1:word.isupper()': word1.isupper(),\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i + 1]\n",
        "        features.update({\n",
        "            '+1:word.lower()': word1.lower(),\n",
        "            '+1:word.istitle()': word1.istitle(),\n",
        "            '+1:word.isupper()': word1.isupper(),\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "    return features\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "def predict_hate_span(sentence):\n",
        "    sentence_tokens = sentence.split()\n",
        "    sentence_features = [sent2features(sentence_tokens)]\n",
        "    predicted_tags = crf_model.predict(sentence_features)[0]\n",
        "    return predicted_tags\n",
        "if __name__ == '__main__':\n",
        "    app.run(port=5500)"
      ],
      "metadata": {
        "id": "BIBFXX7gvGA_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}